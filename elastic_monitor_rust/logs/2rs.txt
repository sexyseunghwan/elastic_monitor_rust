====================================
지마켓 검색엔진 팀 면접 예상질문 및 모범답변 (50개)
====================================

기본상식

[TF-IDF 란?]
TF-IDF: 검색어가 문서 안에서 얼마나 중요한지 수치로 계산하는 공식
*TF (Term Frequency): 단어가 문서 안에 얼마나 자주 등장했는지
*IDF (Inverse Document Frequency): 단어가 전체 문서에서 얼마나 희귀한지
=> 둘을 곱하면 특정 문서에서 특정 단어가 얼마나 의미 있는지가 나옴.

[BM25]
BM25(Okapi BM25) 를 기본점수 알고리즘으로 사용하는 이유는 TF-IDF 의 근본적인 문제들을 해결하면서 훨씬 더 실제 검색 품질에 가까운 점수 모델을 제공하기 때문임



【 Elasticsearch 기초 및 심화 질문 (10개) 】

1. Q: Elasticsearch가 무엇이고, 왜 검색 엔진으로 적합한가요?
   A: Elasticsearch는 Apache Lucene 기반의 분산 검색 및 분석 엔진입니다. 
   1) 실시간에 가까운 검색 속도, 
   2) 수평 확장이 용이한 분산 아키텍처, 
   3) RESTful API 제공으로 쉬운 통합, 
   4) 강력한 전문 검색(Full-text search) 기능, 
   5) JSON 기반의 유연한 스키마 등의 장점이 있습니다. 
   알바천국과 위메프에서 5년 이상 Elasticsearch를 운영하며 상품 검색, 로그 분석 등에 활용했습니다.

2. Q: Elasticsearch의 샤드(Shard)와 레플리카(Replica)에 대해 상세히 설명해주세요.
   A: Primary Shard는 데이터를 분산 저장하는 기본 단위입니다. 
    Replica Shard는 Primary의 복제본으로 
    1) 고가용성 제공 (노드 장애 시 자동 승격), 
    2) 검색 성능 향상 (읽기 요청 분산), 
    3) 데이터 유실 방지 등의 역할을 합니다. 
    알바천국에서 Linux 이관 시 클러스터 구성을 최적화하여 검색 성능을 15% 개선했습니다.

3. Q: Inverted Index(역색인)의 원리와 검색에서의 장점은?
   A: 역색인은 문서가 아닌 단어를 키로 하여 해당 단어가 포함된 문서 목록을 저장하는 방식입니다. 
   예를 들어 "스마트폰"이라는 단어가 어떤 문서에 있는지 즉시 찾을 수 있어 검색 속도가 매우 빠릅니다. 
   Elasticsearch는 역색인을 기반으로 하며, 
   형태소 분석, N-gram, Edge N-gram 등 다양한 토크나이저를 통해 색인을 최적화할 수 있습니다.

4. Q: Elasticsearch의 Analyzer에 대해 설명하고, nori 분석기 사용 경험을 말씀해주세요.
   A: Analyzer는 텍스트를 토큰으로 분리하고 정규화하는 과정을 담당합니다. 
   Character Filter → Tokenizer → Token Filter 순서로 동작합니다. 
   nori는 한글 형태소 분석기로, 위메프에서 상품명/브랜드명 검색에 활용, 알바천국에서는 공고제목, 회사명 등에 확용했습니다. 
   사용자 사전(userdict)을 주기적으로 관리하고, 불용어 처리, edge_ngram 필터를 조합하여 자연어 검색 정확도를 높였습니다.

5. Q: Mustache Template을 사용한 이유와 장점은 무엇인가요?
   A: Mustache Template은 쿼리 로직을 템플릿화하여 관리하는 방식입니다. 
   장점은 
   1) 서비스 개발자와 검색 개발자의 역할 분리,
   2) 쿼리 변경 시 서비스 코드 재배포 불필요,
   3) 버전 관리 용이, 
   4) 보안성 향상(쿼리 로직 노출 방지)입니다. 
   알바천국에서 Rust 기반 템플릿 배포 자동화 파이프라인을 구축하여 배포 시간을 90% 단축했습니다.

6. Q: Elasticsearch에서 매핑(Mapping)이란 무엇이며, Dynamic Mapping의 문제점은?
   A: Mapping은 인덱스의 스키마로, 각 필드의 데이터 타입과 분석 방법을 정의합니다. 
   Dynamic Mapping은 자동으로 타입을 추론하지만, 
   1) 의도하지 않은 타입 지정(예: 숫자를 text로 인식), 
   2) 매핑 충돌 발생 가능, 
   3) 성능 저하 등의 문제가 있습니다. 
   따라서 프로덕션에서는 명시적(static) Mapping을 사용하고, 
   색인 전 매핑을 검증했습니다.
   로그쪽은 동적맵핑 사용

7. Q: Elasticsearch 클러스터의 상태(Green, Yellow, Red)에 대해 설명해주세요.
   A: Green: 모든 Primary/Replica Shard가 정상 할당, 
   Yellow: Primary는 정상이나 일부 Replica 미할당(검색은 가능하나 가용성 저하), 
   Red: 일부 Primary Shard 미할당(데이터 유실 발생). 
   모니터링 시스템을 통해 Yellow 상태 발생 시 즉시 알림을 받고, 노드 증설이나 샤드 재할당으로 Green 상태를 유지했습니다.

8. Q: Bulk API의 장점과 주의사항은?
   A: Bulk API는 여러 문서를 한 번의 요청으로 색인/업데이트/삭제할 수 있어 
   1) 네트워크 오버헤드 감소, 
   2) 색인 속도 대폭 향상, 
   3) 리소스 효율성 증대 등의 장점이 있습니다. 
   주의사항으로는 
   1) 적절한 배치 크기 설정(보통 1000~5000건), 
   2) 에러 핸들링(일부 실패 시 재처리), 
   3) 메모리 사용량 모니터링이 필요합니다.

9. Q: Elasticsearch의 Refresh와 Flush의 차이점은?
   A: Refresh는 메모리의 인덱스 버퍼를 디스크의 Segment로 작성하여 검색 가능하게 만드는 작업(기본 1초마다)이고, 
   Flush는 Translog를 디스크에 영구 저장하는 작업입니다. 
   실시간 검색이 필요하면 refresh_interval을 조정하고, 
   대량 색인 시에는 -1로 설정하여 성능을 최적화했습니다.

   - refresh: 인메모리 버퍼의 문서를 Lucene 세그먼트로 변환하여 검색 가능하게 만드는 작업 -> 디스크에 파일 생성되지만 영속성은 보장하지 않음
   - commit: Lucene 세그 먼트를 fsync()를 통해서 디스크에 안전하게 저장하고, 세그먼트 메타데이터 생성 -> 장애 발생 시 복구 가능한 기준점(영속성 확보)
   - flush: Elasticsearch 수준에서의 강제커밋 + translog 정리 작업 ->  translog 의 내용을 Lucene 세그먼트에 반영 후 삭제가능하게 함
   => commit flush 를 그냥 flush라고 보는거 같음


10. Q: Elasticsearch 클러스터 성능 최적화를 위해 어떤 작업들을 수행하셨나요?
    A: 1) 샤드 개수 최적화(샤드당 20~50GB 유지), 
    2) Replica 개수 조정(읽기 부하에 따라), 
    3) Heap 메모리 설정(물리 메모리의 50% 이하, 32GB 이하), 
    4) Query Cache 및 Request Cache 활용, 
    5) Force Merge로 Segment 병합
    등을 통해 검색 성능을 15% 개선했습니다.


【 검색 알고리즘 및 랭킹 최적화 (8개) 】

11. Q: 전자상거래에서 검색 랭킹 알고리즘을 어떻게 설계하시겠습니까?
    A: 
    1) TF-IDF 기반 관련성 점수, 
    2) 상품 인기도(판매량, 리뷰 수), 
    3) 최신성, 
    4) 가격 경쟁력, 
    5) 유료 광고 가중치, 
    6) 사용자 행동 데이터(클릭률, 구매 전환율) 등을 조합합니다. 
    Elasticsearch의 function_score를 활용하여 각 요소에 가중치를 부여하고, 
    field_value_factor, decay function 등으로 점수를 조정합니다. 
    알바천국에서 유료공고 랭킹 알고리즘을 설계하여 노출량을 25% 증가시켰습니다.

12. Q: BM25 알고리즘에 대해 설명해주세요.
    A: BM25는 Elasticsearch의 기본 스코어링 알고리즘으로, 
    TF-IDF를 개선한 확률론적 랭킹 함수입니다. 
    문서 길이 정규화를 통해 긴 문서가 불리하지 않도록 하고, 용어 빈도(TF)의 포화 효과를 반영합니다. 
    k1(용어 빈도 포화도)과 b(문서 길이 정규화) 파라미터를 조정하여 검색 품질을 최적화할 수 있습니다.

13. Q: 검색 품질을 평가하는 지표는 무엇이 있나요?
    A: 
    1) Precision(정밀도): 검색 결과 중 관련 문서 비율, 
    2) Recall(재현율): 전체 관련 문서 중 검색된 비율, 
    3) MRR(Mean Reciprocal Rank): 첫 관련 문서의 순위, 
    4) NDCG(Normalized Discounted Cumulative Gain): 순위를 고려한 평가, 
    5) CTR(클릭률), 
    6) 전환율 등을 모니터링합니다. A/B 테스트를 통해 알고리즘 변경 효과를 검증했습니다.

14. Q: 동의어(Synonym) 처리는 어떻게 구현하시겠습니까?
    A: Elasticsearch의 Synonym Token Filter를 사용합니다. 
    1) 색인 시(index_analyzer)와 검색 시(search_analyzer) 적용 시점 선택, 
    2) 동의어 사전 파일 관리(동의어 그룹 정의), 
    3) 중앙 집중식 사전 관리 시스템으로 자동 배포, 
    4) expand 옵션으로 모든 동의어 확장 또는 대표어 매핑 선택 등을 고려합니다. "핸드폰, 휴대폰, 스마트폰" 등을 동의어로 처리하여 검색 커버리지를 확대합니다.

15. Q: 검색어 자동완성(Auto-complete)을 어떻게 구현하시겠습니까?
    A: 
    1) Elasticsearch의 Completion Suggester 사용(빠른 응답), 
    2) Edge N-gram Tokenizer로 부분 일치 검색 구현, 
    3) Redis에 인기 검색어 캐싱(응답 속도 최적화), 
    4) 사용자 검색 로그 분석으로 추천어 생성,
    5) Prefix 기반 FST(Finite State Transducer) 활용 등의 방법을 조합합니다. 
    초성 검색도 지원하려면 초성 분리 필터를 추가합니다.

16. Q: 오타 교정(Spell Correction)은 어떻게 처리하시겠습니까?
    A: 
    1) Elasticsearch의 Suggest API(Term Suggester, Phrase Suggester) 활용, 
    2) Edit Distance(Levenshtein Distance) 기반 유사어 검색, 
    3) N-gram 기반 부분 일치, 
    4) 사용자 검색 로그에서 자주 검색되는 단어로 교정, 
    5) "혹시 이것을 찾으셨나요?" 형태로 제안 등을 구현합니다. 
    Fuzzy Query를 활용하여 1~2자 오타까지 허용할 수 있습니다.

17. Q: 개인화 검색을 구현한다면 어떻게 하시겠습니까?
    A: 
    1) 사용자 행동 로그 수집(클릭, 구매, 찜 등), 
    2) 사용자 프로필 정보 활용(연령, 성별, 지역), 
    3) 협업 필터링으로 유사 사용자 패턴 분석, 
    4) Elasticsearch의 Rescore로 개인화 점수 추가, 
    5) Redis에 사용자별 선호 카테고리 캐싱 등을 적용합니다. 개인정보 보호를 고려하여 익명화 및 동의 절차를 거칩니다.

18. Q: 필터(Filter)와 쿼리(Query)의 차이점과 사용 전략은?
    A: Query는 스코어링을 수행하여 관련성 점수를 계산하고, 
    Filter는 단순 Yes/No 판단으로 스코어링하지 않습니다. Filter는 캐싱되어 성능이 우수하므로, 
    1) 정확한 일치 조건(카테고리, 가격 범위, 재고 여부)은 Filter 사용,
    2) 텍스트 검색은 Query 사용, 
    3) Bool Query의 filter 절 활용 등의 전략으로 성능을 최적화합니다.


【 시스템 아키텍처 및 인프라 (10개) 】

19. Q: Elasticsearch 클러스터 아키텍처를 어떻게 설계하시겠습니까?
    A: 
    1) 노드 역할 분리(Master, Data, Coordinating), 
    2) Master 노드 3개 이상 홀수로 구성(Split Brain 방지),
    3) Hot-Warm-Cold 아키텍처(데이터 라이프사이클 관리), 
    4) 전용 Coordinating 노드로 부하 분산, 
    5) Dedicated Master 노드로 클러스터 안정성 확보 등을 고려합니다. 규모에 따라 노드 역할을 세분화합니다.

20. Q: Kafka를 검색 시스템에서 어떻게 활용하셨나요?
    A: 
    1) 사용자 행동 로그 실시간 수집, 
    2) 검색 쿼리 로그 스트리밍, 
    3) 색인 데이터 파이프라인 구축(DB → Kafka → Elasticsearch), 
    4) 이벤트 기반 아키텍처 구현 등에 활용했습니다. 위메프에서 Kafka 2.5.0을 3.3.1로 업그레이드하고, 토픽 설계 및 파티션 복제를 최적화하여 안정성을 향상시켰습니다.
    
21. Q: Redis를 검색 시스템에서 어떻게 활용하시겠습니까?
    A: 
    1) 검색 결과 캐싱(자주 검색되는 쿼리), 
    2) 인기 검색어 실시간 집계(Sorted Set), 
    3) 자동완성 후보 캐싱(String, Hash), 
    4) Rate Limiting(API 호출 제한), 
    5) Session 관리, 
    6) 실시간 랭킹 계산 등에 활용합니다. 
    위메프에서 Master-Slave 클러스터를 구축하고 TTL 없는 키를 정리하여 메모리 효율성을 개선했습니다.

22. Q: ELK에서 EVK로 변경한 이유와 Vector의 장점은?
    A: Logstash는 JVM 기반으로 메모리 사용량이 크고 성능 오버헤드가 있습니다. 
    Vector는 Rust로 작성되어 
    1) 낮은 메모리 사용량, 
    2) 높은 처리 속도, 
    3) 간결한 설정, 
    4) 강력한 데이터 변환 기능 등의 장점이 있습니다. 
    위메프에서 EVK로 전환하여 메모리 사용량 40% 감소, 데이터 처리 속도 60% 향상을 달성했습니다.

23. Q: Elasticsearch를 Windows에서 Linux로 이관한 이유와 과정은?
    A: Linux는 
    1) 오픈소스로 라이선스 비용 절감, 
    2) 성능 및 안정성 우수, 
    3) 자동화 도구와 높은 호환성, 
    4) 대규모 분산 시스템에 적합 등의 이점이 있습니다. 
    
    이관 과정은 
    1) 신규 Linux 클러스터 구축, 
    2) Mustache 템플릿 및 매핑 동기화, 
    3) 색인 데이터 단계적 이전, 
    4) Analyzer 및 매핑 호환성 검증, 
    5) 모니터링 재구성 등을 수행했습니다. 
    
    데이터 무결성 100% 유지하며 성능 15% 개선했습니다.


24. Q: 대용량 데이터 색인 시 성능 최적화 방법은?
    A: 
    1) Refresh Interval을 -1로 설정하여 색인 중 비활성화, 
    2) Replica를 0으로 설정 후 색인 완료 후 복원, 
    3) Bulk API로 배치 처리(1000~5000건), 
    4) 색인 스레드 수 조정, 
    5) Translog 동기화 주기 조정, 
    6) Force Merge로 Segment 병합 등을 적용합니다. 
    색인 완료 후 반드시 Replica와 Refresh를 복원합니다.

25. Q: Elasticsearch의 보안은 어떻게 구성하셨나요?
    A: 
    1) X-Pack Security 또는 Search Guard 적용, 
    2) TLS/SSL 암호화 통신, 
    3) 역할 기반 접근 제어(RBAC), 
    4) 네트워크 레벨 방화벽 설정, 
    5) API Key 인증, 
    6) 감사 로그(Audit Logging) 활성화 등으로 보안을 강화했습니다. 
    부서별로 접근 권한을 세분화하여 데이터 보안성을 높였습니다.

26. Q: Elasticsearch 클러스터의 스케일링 전략은?
    A: 수직 확장(Scale-up): CPU, 메모리 증설로 단일 노드 성능 향상. 
    수평 확장(Scale-out): 노드 추가로 분산 처리 능력 증대. 
    Elasticsearch는 수평 확장에 적합하며, 
    1) 데이터 노드 추가 시 자동 샤드 재분배, 
    2) Coordinating 노드 추가로 부하 분산 등을 고려합니다. 
    알바천국에서 Linux 환경으로 전환하여 확장성을 크게 개선했습니다.

27. Q: 검색 시스템의 고가용성(HA)은 어떻게 확보하시겠습니까?
    A: 
    1) Replica Shard 최소 1개 이상 설정, 
    2) 다중 노드 구성 (최소 3개), 
    3) 로드 밸런서를 통한 트래픽 분산, 
    4) 자동 Failover 구성, 
    5) 모니터링 및 알림 시스템, 
    6) 정기적인 스냅샷 백업, 
    7) 재해 복구 계획(DR) 수립 등으로 고가용성을 확보합니다. 
    Red / Yellow 상태 발생 시 즉시 대응하여 Green 유지했습니다.

28. Q: 검색 API의 응답 속도를 개선하는 방법은?
    A: 
    1) Redis 캐싱 (자주 요청되는 검색), 
    2) Elasticsearch Query Cache 활용, 
    3) 적절한 샤드 라우팅, 
    4) 필요한 필드만 반환(_source filtering), 
    5) Pagination 최적화(scroll 대신 search_after), 
    6) Aggregation 최적화, 
    7) CDN 활용(정적 데이터) 등을 적용합니다. 
    응답 시간을 최대 15% 개선했습니다.


【 프로그래밍 및 개발 역량 (8개) 】

29. Q: Rust를 선택한 이유와 실무에서의 활용 경험은?
    A: Rust는 
    1) 메모리 안정성(소유권 시스템), 
    2) C/C++ 수준의 성능, 
    3) 안전한 동시성 처리, 
    4) Zero-cost Abstraction, 
    5) 강력한 타입 시스템 등의 장점이 있습니다. 
    알바천국에서 
    1) Mustache 템플릿 배포 자동화, 
    2) Elasticsearch 모니터링 시스템, 
    3) 사전 동기화 시스템 등을 Rust로 개발하여 고성능과 안정성을 달성했습니다. 
    또한 위메프에서는 RUST 를 사용하여 멀티스레드 프로그래밍으로 Redis 키 수집 성능을 극대화했습니다.

30. Q: Java 개발 경험과 Spring 프레임워크 사용 경험은? (이건 좀...)
    A: 위메프에서 Java + JPA 기반의 색인 처리 모듈을 운영했습니다.
    1) Spring Boot로 색인 API 개발, 
    2) JPA로 DB 연동 및 변경 감지, 
    3) Hibernate 최적화, 
    4) 트랜잭션 관리, 
    5) 스케줄러를 통한 배치 작업 등을 수행했습니다. 
    DB 변경사항을 실시간으로 Elasticsearch에 반영하는 파이프라인을 구축했습니다.

31. Q: Git을 활용한 형상관리와 협업 경험은?
    A: 
    1) Git Flow 브랜치 전략(develop, release, hotfix),
    2) Pull Request를 통한 코드 리뷰, 
    3) Merge 전략(Squash, Rebase), 
    4) Conflict 해결, 
    5) GitLens로 변경 이력 추적 등을 활용했습니다.
    알바천국에서 Mustache 템플릿을 Git으로 버전 관리하고, 
    개발/운영 브랜치를 분리하여 환경별 배포를 자동화했습니다.

32. Q: CI/CD 파이프라인 구축 경험을 설명해주세요.
    A: Jenkins Pipeline을 구축하여 
    1) Git Webhook으로 자동 빌드 트리거, 
    2) 개발/운영 브랜치 분리, 
    3) 단위 테스트 자동 실행, 
    4) 빌드 아티팩트 생성, 
    5) 자동 배포(Mustache 템플릿 → Elasticsearch), 
    6) 배포 결과 알림(Slack, Email) 등을 구성했습니다. 배포 시간을 기존 수작업 대비 90% 단축했습니다.

33. Q: Python 개발 경험과 데이터 분석 활용 사례는?
    A: Python으로 
    1) Elasticsearch 데이터 추출 및 분석, 
    2) Metricbeat 커스텀 스크립트, 
    3) Redis Slowlog 수집 도구, 
    4) 로그 분석 및 시각화(Pandas, Matplotlib), 
    5) 자동화 스크립트 개발 등을 수행했습니다. 
    특히 Redis 클러스터의 Slowlog와 Latency를 Python으로 수집하여 Elasticsearch에 저장하고 모니터링했었습니다.
    (지금은 RUST 로 전환)

34. Q: RESTful API 설계 원칙과 경험은?
    A: RESTful API 설계 시 
    1) 리소스 중심 URL 설계, 
    2) HTTP Method 적절히 사용(GET, POST, PUT, DELETE), 
    3) 상태 코드 명확히 반환(200, 201, 400, 404, 500), 
    4) 버저닝 전략(URI 또는 Header), 
    5) 페이지네이션 및 필터링 지원 등을 고려합니다. 
    Elasticsearch와의 통신도 RESTful API를 통해 수행하며, 효율적인 쿼리 구조를 설계했습니다.

35. Q: 성능 프로파일링과 병목 지점 해결 경험은?
    A: 
    1) Elasticsearch Slow Query Log 분석, 
    2) JVM Heap Dump 분석, 
    3) Linux 명령어(top, iostat, vmstat)로 리소스 모니터링, 
    4) APM 도구 활용, 
    5) 쿼리 실행 계획 분석 등으로 병목을 파악했습니다. 인덱스 재구성, 쿼리 최적화, 캐싱 적용 등으로 응답 속도를 개선했습니다.

36. Q: 테스트 코드 작성 경험과 테스트 전략은?
    A: 
    1) 단위 테스트(JUnit, pytest)로 개별 함수 검증, 
    2) 통합 테스트로 시스템 간 연동 검증, 
    3) 성능 테스트(JMeter, Locust)로 부하 테스트, 
    4) A/B 테스트로 알고리즘 효과 검증 등을 수행했습니다. 
    Mustache 템플릿 배포 전 반드시 테스트 환경에서 검증 후 운영 반영했습니다.


【 데이터베이스 및 쿼리 최적화 (6개) 】

37. Q: SQL Server Stored Procedure 튜닝 경험을 상세히 설명해주세요.
    A: 지오시스에서 DA로 근무하며 
    1) 실행 계획 분석(Execution Plan), 
    2) 인덱스 스캔 → 인덱스 시크로 개선, 
    3) 불필요한 조인 제거, 
    4) WHERE 절 최적화(SARGable), 
    5) 통계 정보 업데이트, 
    6) 파라미터 스니핑 문제 해결, 
    7) 임시 테이블 대신 테이블 변수 활용 등으로 SP 성능을 개선했습니다. 응답 시간을 평균 30% 단축했습니다.

38. Q: 인덱스 설계 원칙과 최적화 방법은?
    A: 
    1) 선택도(Selectivity)가 높은 컬럼 우선, 
    2) WHERE, JOIN, ORDER BY에 자주 사용되는 컬럼,
    3) Covering Index로 Include 컬럼 활용, 
    4) Clustered vs Non-clustered 선택, 
    5) 인덱스 크기 최소화, 
    6) 불필요한 인덱스 제거(쓰기 성능 향상), 
    7) Index Fragmentation 관리 등을 고려합니다. 지오시스에서 적절한 인덱스 설계로 쿼리 성능을 대폭 향상시켰습니다.

39. Q: ERD 설계 및 데이터 모델링 경험은?
    A: 위메프, 큐텐, 티몬의 ERD 통합 작업을 수행했습니다. 
    1) 요구사항 분석 및 엔티티 도출, 
    2) 정규화(1NF~3NF)로 데이터 중복 제거, 
    3) 관계 설정(1:1, 1:N, N:M), 
    4) DA# 및 ERWIN Tool 활용, 
    5) 물리 모델 설계(테이블, 컬럼, 제약조건) 등을 수행했습니다. 체계적인 ERD 관리로 아키텍처 투명성을 높였습니다.

40. Q: NoSQL과 RDBMS를 어떤 기준으로 선택하시겠습니까?
    A: 
    RDBMS 선택 기준: 
    1) ACID 트랜잭션 필요, 
    2) 복잡한 조인 및 집계, 
    3) 정형 데이터, 
    4) 데이터 일관성 중요. 
    
    NoSQL 선택 기준: 
    1) 수평 확장 필요, 
    2) 유연한 스키마, 
    3) 높은 처리량, 
    4) 비정형 데이터. 
    예: 주문 데이터는 RDBMS, 검색 엔진은 Elasticsearch, 캐싱은 Redis, 로그는 Kafka+Elasticsearch를 사용합니다.

41. Q: 데이터베이스 파티셔닝 전략은?
    A: 
    1) Range Partitioning: 날짜 기반(로그, 주문 데이터), 
    2) Hash Partitioning: 균등 분산(사용자 ID), 
    3) List Partitioning: 카테고리별(지역, 상태), 
    4) Composite Partitioning: 복합 전략. 파티셔닝의 장점은 쿼리 성능 향상, 관리 용이성, 백업/복구 효율성 등입니다. Elasticsearch의 샤딩도 일종의 파티셔닝 전략입니다.

42. Q: 트랜잭션 격리 수준(Isolation Level)에 대해 설명해주세요.
    A: 
    1) Read Uncommitted: Dirty Read 발생, 
    2) Read Committed: Dirty Read 방지, 
    3) Repeatable Read: Non-repeatable Read 방지, 
    4) Serializable: Phantom Read 방지(최고 수준). 격리 수준이 높을수록 일관성은 높지만 동시성은 낮아집니다. 
    일반적으로 Read Committed를 사용하고, 필요 시 Repeatable Read를 적용했습니다.


【 모니터링 및 장애 대응 (6개) 】

43. Q: Elasticsearch 클러스터 모니터링 시스템 구축 경험은?
    A: Rust로 로그 수집 시스템을 개발하여 
    1) CPU, Memory, Disk 사용량, 
    2) Shard 수 및 상태, 
    3) Query Cache 사용률, 
    4) GC 메트릭, 
    5) 검색 요청 통계 등을 수집했습니다. 
    Grafana로 실시간 대시보드를 구축하고, 임계치 초과 시 Telegram으로 알림을 받도록 구성했습니다. 장애 대응 시간을 30분에서 10분으로 단축했습니다.

44. Q: 검색 시스템 장애 발생 시 대응 프로세스는?
    A: 
    1) 알림 수신 및 현상 파악(Grafana, Kibana), 
    2) 로그 분석(Slow Query, Error Log), 
    3) 클러스터 상태 확인(Green/Yellow/Red), 
    4) 긴급 조치(문제 쿼리 차단, 노드 재시작), 
    5) 근본 원인 분석, 
    6) 재발 방지 대책 수립, 
    7) 사후 보고서 작성 등의 프로세스로 대응합니다. 
    모니터링 시스템으로 사전 예방에 주력했습니다.

45. Q: Slow Query를 어떻게 식별하고 해결하셨나요?
    A: 
    1) Elasticsearch Slow Query Log 분석 (index.search.slowlog 설정), 
    2) Kibana에서 실행 시간 긴 쿼리 추출, 
    3) Profile API로 쿼리 실행 단계 분석, 
    4) 불필요한 와일드카드 쿼리 제거, 
    5) Aggregation 최적화, 
    6) 필터 조건 추가로 검색 범위 축소, 
    7) 캐싱 적용 등으로 해결했습니다.

46. Q: 로그 관리 및 분석 전략은?
    A: 
    1) 구조화된 로그 포맷(JSON), 
    2) 로그 레벨 분리(DEBUG, INFO, WARN, ERROR), 
    3) ELK/EVK 스택으로 중앙 집중식 관리, 
    4) 보존 정책(ILM)으로 오래된 로그 삭제, 
    5) 검색 및 시각화(Kibana), 
    6) 알림 규칙 설정 등으로 관리합니다. 
    위메프에서 API → Kafka → Elasticsearch 파이프라인을 구축하여 통합 로그를 관리했습니다.

47. Q: Heartbeat를 활용한 헬스체크 경험은?
    A: Heartbeat로 
    1) Elasticsearch 노드 가용성 체크, 
    2) Redis 클러스터 연결 체크, 
    3) Kafka 브로커 상태 체크, 
    4) API 엔드포인트 응답 시간 측정 등을 수행했습니다. 
    특정 노드 연결 실패 시 즉시 Telegram 알림을 받아 빠른 대응이 가능했습니다.

48. Q: 백업 및 복구 전략은?
    A: Elasticsearch: 
    1) Snapshot API로 정기 백업(S3, NFS), 
    2) ILM 정책으로 자동 스냅샷, 
    3) 복구 테스트 정기 수행. 
    
    RDBMS: 
    1) 전체 백업 + 증분 백업, 
    2) Point-in-time Recovery, 
    3) 다중 백업 보관(3-2-1 규칙). 
    재해 복구 계획(DR)을 수립하여 RTO/RPO를 정의하고, 복구 절차를 문서화했습니다.


【 협업 및 커뮤니케이션 (4개) 】

49. Q: 서비스 개발팀과의 협업 경험과 커뮤니케이션 방식은?
    A: 
    1) Mustache Template 방식으로 역할 분리, 
    2) API 사용 가이드 문서 작성, 
    3) 정기 미팅으로 요구사항 수렴, 
    4) 템플릿 변경 프로세스 협의 및 문서화, 
    5) Git을 통한 변경 이력 공유 등으로 협업했습니다. 
    서비스 개발자는 파라미터만 전달하고, 검색 로직은 검색 개발자가 관리하여 전문성을 높였습니다.

50. Q: 검색 품질 개선을 위해 다른 부서와 어떻게 협업하시겠습니까?
    A: 
    1) 기획팀: 비즈니스 요구사항 및 검색 전략 협의, 
    2) 데이터 분석팀: 사용자 행동 로그 분석 및 검색 패턴 파악, 
    3) 인프라팀: 클러스터 증설 및 성능 최적화, 
    4) 운영팀: 장애 대응 및 모니터링 체계 구축, 
    5) UX/UI팀: 검색 결과 화면 개선 등 다양한 부서와 협업하여 통합적인 검색 품질 향상을 추구합니다.


====================================
작성일: 2025년 12월 8일
====================================